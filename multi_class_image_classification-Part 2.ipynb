{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary package\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the .csv file to a variable.\n",
    "label=pd.read_csv(\"/Users/rohitbohra/Documents/aptos2019-blindness-detection/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00cb6555d108.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0124dffecf29.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           id_code  diagnosis\n",
       "0           0  000c1434d8d7.png          2\n",
       "1           1  00a8624548a9.png          2\n",
       "2           2  00cb6555d108.png          1\n",
       "3           3  0104b032c141.png          3\n",
       "4           4  0124dffecf29.png          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows in the dataframe.\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0', 'id_code', 'diagnosis']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column of the datasets\n",
    "list(label.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_code', 'diagnosis']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the unnecessary column from the dataframe\n",
    "label=label.drop(['Unnamed: 0'], axis=1)\n",
    "list(label.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00a8624548a9.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00cb6555d108.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0104b032c141.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0124dffecf29.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_code  diagnosis\n",
       "0  000c1434d8d7.png          2\n",
       "1  00a8624548a9.png          2\n",
       "2  00cb6555d108.png          1\n",
       "3  0104b032c141.png          3\n",
       "4  0124dffecf29.png          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows of data\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required packages\n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "path=\"/Users/rohitbohra/Documents/aptos2019-blindness-detection/train_images/\"\n",
    "\n",
    "#functiion for resizing the images\n",
    "def get_image(path, id_code, size):\n",
    "    img_path = os.path.join(path, id_code)\n",
    "    image = cv2.imread(img_path)  \n",
    "    image = cv2.resize(image, (size,size))\n",
    "    image_arr = image.reshape( size,size, 3).astype('float32')/255\n",
    "    #print(image_arr.shape)\n",
    "    return image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the image shape\n",
    "all_images = []\n",
    "all_images.append(label['id_code'].apply(lambda code: get_image('/Users/rohitbohra/Documents/aptos2019-blindness-detection/train_images/',code, 96)))\n",
    "x_train = np.array(all_images)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[1], 96,96, 3).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels of the dataset to be assigned to a variable\n",
    "y_train = label['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitbohra/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# converting the label into categorical data\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# number of classes\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting of dataset into train and test data with 80 - 20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_on=open(\"X_train.pickle\",'wb')\n",
    "pickle.dump(X_train,pickle_on)\n",
    "pickle_on.close()\n",
    "\n",
    "pickle_on=open(\"y_train.pickle\",'wb')\n",
    "pickle.dump(y_train,pickle_on)\n",
    "pickle_on.close()\n",
    "\n",
    "pickle_on=open(\"X_test.pickle\",'wb')\n",
    "pickle.dump(X_test,pickle_on)\n",
    "pickle_on.close()\n",
    "\n",
    "pickle_on=open(\"y_test.pickle\",'wb')\n",
    "pickle.dump(y_test,pickle_on)\n",
    "pickle_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 96, 96, 3)\n",
      "(743, 5)\n",
      "(186, 96, 96, 3)\n",
      "(186, 5)\n"
     ]
    }
   ],
   "source": [
    "pickle_off = open(\"X_train.pickle\",'rb')\n",
    "X_train=pickle.load(pickle_off)\n",
    "print(X_train.shape)\n",
    "\n",
    "pickle_off = open(\"y_train.pickle\",'rb')\n",
    "y_train=pickle.load(pickle_off)\n",
    "print(y_train.shape)\n",
    "\n",
    "pickle_off = open(\"X_test.pickle\",'rb')\n",
    "X_test=pickle.load(pickle_off)\n",
    "print(X_test.shape)\n",
    "\n",
    "pickle_off = open(\"y_test.pickle\",'rb')\n",
    "y_test=pickle.load(pickle_off)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743, 96, 96, 3)\n",
      "(186, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of the train data and test data\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the packages for Neural Network uisng keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, GaussianNoise, GaussianDropout\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a function with the required layers and regularization layers added'\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(15, (9, 9), input_shape=[96,96,3], activation='relu'))\n",
    "    model.add(GaussianDropout(0.3))\n",
    "    model.add(Conv2D(30, (7, 7), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, (7, 7), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(50, (7, 7), activation='relu'))\n",
    "    model.add(Conv2D(50, (5, 5), activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n",
    "                   ,activity_regularizer=regularizers.l1(0.01)))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using early stopping which will automatically stop the training of data when there is no improvement of the loss in test data\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 10)\n",
    "mc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 743 samples, validate on 186 samples\n",
      "Epoch 1/1000\n",
      "743/743 [==============================] - 62s 84ms/step - loss: 4.4149 - acc: 0.5047 - val_loss: 2.8607 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.86069, saving model to model.h5\n",
      "Epoch 2/1000\n",
      "743/743 [==============================] - 62s 84ms/step - loss: 2.3953 - acc: 0.5087 - val_loss: 1.9695 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.86069 to 1.96951, saving model to model.h5\n",
      "Epoch 3/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.8223 - acc: 0.5087 - val_loss: 1.7015 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.96951 to 1.70146, saving model to model.h5\n",
      "Epoch 4/1000\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.6478 - acc: 0.5087 - val_loss: 1.6103 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.70146 to 1.61034, saving model to model.h5\n",
      "Epoch 5/1000\n",
      "743/743 [==============================] - 61s 82ms/step - loss: 1.6065 - acc: 0.5087 - val_loss: 1.5511 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61034 to 1.55107, saving model to model.h5\n",
      "Epoch 6/1000\n",
      "743/743 [==============================] - 64s 85ms/step - loss: 1.5529 - acc: 0.5141 - val_loss: 1.6386 - val_acc: 0.5538\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.55107\n",
      "Epoch 7/1000\n",
      "743/743 [==============================] - 62s 83ms/step - loss: 1.5120 - acc: 0.5195 - val_loss: 1.5896 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.55107\n",
      "Epoch 8/1000\n",
      "743/743 [==============================] - 66s 89ms/step - loss: 1.4797 - acc: 0.5707 - val_loss: 1.4859 - val_acc: 0.6075\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.55107 to 1.48587, saving model to model.h5\n",
      "Epoch 9/1000\n",
      "743/743 [==============================] - 68s 91ms/step - loss: 1.3777 - acc: 0.6272 - val_loss: 1.3449 - val_acc: 0.6344\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.48587 to 1.34492, saving model to model.h5\n",
      "Epoch 10/1000\n",
      "743/743 [==============================] - 63s 84ms/step - loss: 1.3631 - acc: 0.6231 - val_loss: 1.8319 - val_acc: 0.5161\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.34492\n",
      "Epoch 11/1000\n",
      "743/743 [==============================] - 62s 83ms/step - loss: 1.3611 - acc: 0.6447 - val_loss: 1.3097 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.34492 to 1.30972, saving model to model.h5\n",
      "Epoch 12/1000\n",
      "743/743 [==============================] - 61s 82ms/step - loss: 1.2927 - acc: 0.6555 - val_loss: 1.3025 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.30972 to 1.30254, saving model to model.h5\n",
      "Epoch 13/1000\n",
      "743/743 [==============================] - 62s 84ms/step - loss: 1.2211 - acc: 0.7026 - val_loss: 1.2924 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.30254 to 1.29235, saving model to model.h5\n",
      "Epoch 14/1000\n",
      "743/743 [==============================] - 63s 84ms/step - loss: 1.2188 - acc: 0.6904 - val_loss: 1.2529 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.29235 to 1.25291, saving model to model.h5\n",
      "Epoch 15/1000\n",
      "743/743 [==============================] - 65s 87ms/step - loss: 1.1989 - acc: 0.6864 - val_loss: 1.3140 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.25291\n",
      "Epoch 16/1000\n",
      "743/743 [==============================] - 62s 83ms/step - loss: 1.2323 - acc: 0.6837 - val_loss: 1.2338 - val_acc: 0.7419\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.25291 to 1.23385, saving model to model.h5\n",
      "Epoch 17/1000\n",
      "743/743 [==============================] - 62s 84ms/step - loss: 1.1616 - acc: 0.7133 - val_loss: 1.2034 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.23385 to 1.20341, saving model to model.h5\n",
      "Epoch 18/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1743 - acc: 0.7214 - val_loss: 1.2672 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.20341\n",
      "Epoch 19/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1633 - acc: 0.7066 - val_loss: 1.2124 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.20341\n",
      "Epoch 20/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.1533 - acc: 0.6985 - val_loss: 1.2355 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.20341\n",
      "Epoch 21/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1217 - acc: 0.6985 - val_loss: 1.1707 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.20341 to 1.17067, saving model to model.h5\n",
      "Epoch 22/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.0942 - acc: 0.7079 - val_loss: 1.1866 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.17067\n",
      "Epoch 23/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1107 - acc: 0.7268 - val_loss: 1.1791 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.17067\n",
      "Epoch 24/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1279 - acc: 0.7227 - val_loss: 1.1853 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.17067\n",
      "Epoch 25/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.1105 - acc: 0.7174 - val_loss: 1.2457 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.17067\n",
      "Epoch 26/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.2064 - acc: 0.7227 - val_loss: 1.2330 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.17067\n",
      "Epoch 27/1000\n",
      "743/743 [==============================] - 62s 83ms/step - loss: 1.1426 - acc: 0.7201 - val_loss: 1.2331 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.17067\n",
      "Epoch 28/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1474 - acc: 0.7133 - val_loss: 1.2322 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.17067\n",
      "Epoch 29/1000\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1408 - acc: 0.7066 - val_loss: 1.2031 - val_acc: 0.6828\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.17067\n",
      "Epoch 30/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.1143 - acc: 0.7187 - val_loss: 1.2148 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.17067\n",
      "Epoch 31/1000\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.1066 - acc: 0.7214 - val_loss: 1.2156 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.17067\n",
      "Epoch 00031: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f474a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model and checking how the model performs\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test),epochs=1000, batch_size=32, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 743 samples, validate on 186 samples\n",
      "Epoch 1/20\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1116 - acc: 0.7254 - val_loss: 1.1779 - val_acc: 0.6828\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.17067\n",
      "Epoch 2/20\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1092 - acc: 0.7079 - val_loss: 1.1991 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.17067\n",
      "Epoch 3/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.1018 - acc: 0.7201 - val_loss: 1.2092 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17067\n",
      "Epoch 4/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.0971 - acc: 0.7227 - val_loss: 1.2166 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17067\n",
      "Epoch 5/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.0815 - acc: 0.7322 - val_loss: 1.2140 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17067\n",
      "Epoch 6/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.0977 - acc: 0.7281 - val_loss: 1.2458 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17067\n",
      "Epoch 7/20\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1037 - acc: 0.7362 - val_loss: 1.1983 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17067\n",
      "Epoch 8/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.1071 - acc: 0.7268 - val_loss: 1.2300 - val_acc: 0.7473\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17067\n",
      "Epoch 9/20\n",
      "743/743 [==============================] - 60s 80ms/step - loss: 1.1573 - acc: 0.7079 - val_loss: 1.2441 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.17067\n",
      "Epoch 10/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.1431 - acc: 0.7026 - val_loss: 1.2414 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.17067\n",
      "Epoch 11/20\n",
      "743/743 [==============================] - 67s 90ms/step - loss: 1.0992 - acc: 0.7174 - val_loss: 1.1559 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.17067 to 1.15591, saving model to model.h5\n",
      "Epoch 12/20\n",
      "743/743 [==============================] - 68s 91ms/step - loss: 1.0830 - acc: 0.7416 - val_loss: 1.1671 - val_acc: 0.6989\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.15591\n",
      "Epoch 13/20\n",
      "743/743 [==============================] - 61s 83ms/step - loss: 1.0678 - acc: 0.7443 - val_loss: 1.1838 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.15591\n",
      "Epoch 14/20\n",
      "743/743 [==============================] - 59s 79ms/step - loss: 1.0760 - acc: 0.7281 - val_loss: 1.2080 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.15591\n",
      "Epoch 15/20\n",
      "743/743 [==============================] - 59s 79ms/step - loss: 1.0732 - acc: 0.7214 - val_loss: 1.2278 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.15591\n",
      "Epoch 16/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.0728 - acc: 0.7429 - val_loss: 1.2052 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.15591\n",
      "Epoch 17/20\n",
      "743/743 [==============================] - 59s 79ms/step - loss: 1.0690 - acc: 0.7281 - val_loss: 1.3196 - val_acc: 0.6828\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.15591\n",
      "Epoch 18/20\n",
      "743/743 [==============================] - 59s 80ms/step - loss: 1.0978 - acc: 0.7254 - val_loss: 1.2295 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.15591\n",
      "Epoch 19/20\n",
      "743/743 [==============================] - 59s 79ms/step - loss: 1.0706 - acc: 0.7389 - val_loss: 1.2184 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.15591\n",
      "Epoch 20/20\n",
      "743/743 [==============================] - 60s 81ms/step - loss: 1.0509 - acc: 0.7402 - val_loss: 1.2059 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.15591\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data = (X_test, y_test),epochs=20, batch_size=32, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic_val(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Accuracy\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6881720423698425\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the accuracy of model on test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test Accuracy:', score[1]) \n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('categorical_crossentropy')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,21))\n",
    "\n",
    "vy = history.history['acc']\n",
    "ty = history.history['val_acc']\n",
    "plt_dynamic_val(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(250, (9, 9), input_shape=[96,96,3], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(230, (7, 7), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(150, (7, 7), activation='relu'))\n",
    "    model.add(Conv2D(130, (5, 5), activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(526, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(254, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n",
    "                   ,activity_regularizer=regularizers.l1(0.01)))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 10)\n",
    "mc = ModelCheckpoint('model1.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 743 samples, validate on 186 samples\n",
      "Epoch 1/1000\n",
      "743/743 [==============================] - 2048s 3s/step - loss: 7.0873 - acc: 0.4320 - val_loss: 4.3630 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.36305, saving model to model1.h5\n",
      "Epoch 2/1000\n",
      "743/743 [==============================] - 2033s 3s/step - loss: 3.4804 - acc: 0.4939 - val_loss: 2.5054 - val_acc: 0.5054\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.36305 to 2.50539, saving model to model1.h5\n",
      "Epoch 3/1000\n",
      "743/743 [==============================] - 2042s 3s/step - loss: 2.0686 - acc: 0.6083 - val_loss: 1.7245 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.50539 to 1.72454, saving model to model1.h5\n",
      "Epoch 4/1000\n",
      "743/743 [==============================] - 2035s 3s/step - loss: 1.6085 - acc: 0.6662 - val_loss: 1.5034 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72454 to 1.50343, saving model to model1.h5\n",
      "Epoch 5/1000\n",
      "743/743 [==============================] - 2031s 3s/step - loss: 1.4224 - acc: 0.6810 - val_loss: 1.4736 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.50343 to 1.47365, saving model to model1.h5\n",
      "Epoch 6/1000\n",
      "743/743 [==============================] - 2035s 3s/step - loss: 1.3372 - acc: 0.6541 - val_loss: 1.3208 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.47365 to 1.32081, saving model to model1.h5\n",
      "Epoch 7/1000\n",
      "743/743 [==============================] - 2031s 3s/step - loss: 1.2472 - acc: 0.6931 - val_loss: 1.3313 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.32081\n",
      "Epoch 8/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.2849 - acc: 0.6904 - val_loss: 1.3705 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.32081\n",
      "Epoch 9/1000\n",
      "743/743 [==============================] - 2027s 3s/step - loss: 1.4372 - acc: 0.6756 - val_loss: 1.5813 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.32081\n",
      "Epoch 10/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.4802 - acc: 0.6703 - val_loss: 1.4020 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.32081\n",
      "Epoch 11/1000\n",
      "743/743 [==============================] - 2030s 3s/step - loss: 1.2719 - acc: 0.6797 - val_loss: 1.2468 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.32081 to 1.24681, saving model to model1.h5\n",
      "Epoch 12/1000\n",
      "743/743 [==============================] - 2033s 3s/step - loss: 1.1908 - acc: 0.6904 - val_loss: 1.1926 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.24681 to 1.19263, saving model to model1.h5\n",
      "Epoch 13/1000\n",
      "743/743 [==============================] - 2042s 3s/step - loss: 1.1548 - acc: 0.6904 - val_loss: 1.1907 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.19263 to 1.19069, saving model to model1.h5\n",
      "Epoch 14/1000\n",
      "743/743 [==============================] - 2179s 3s/step - loss: 1.1340 - acc: 0.6810 - val_loss: 1.1854 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.19069 to 1.18544, saving model to model1.h5\n",
      "Epoch 15/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1410 - acc: 0.7039 - val_loss: 1.1972 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.18544\n",
      "Epoch 16/1000\n",
      "743/743 [==============================] - 2028s 3s/step - loss: 1.1345 - acc: 0.6972 - val_loss: 1.2754 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.18544\n",
      "Epoch 17/1000\n",
      "743/743 [==============================] - 2030s 3s/step - loss: 1.1917 - acc: 0.6891 - val_loss: 1.2079 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.18544\n",
      "Epoch 18/1000\n",
      "743/743 [==============================] - 2038s 3s/step - loss: 1.1306 - acc: 0.6891 - val_loss: 1.1864 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.18544\n",
      "Epoch 19/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1248 - acc: 0.6999 - val_loss: 1.1829 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.18544 to 1.18293, saving model to model1.h5\n",
      "Epoch 20/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.0996 - acc: 0.7052 - val_loss: 1.1656 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.18293 to 1.16563, saving model to model1.h5\n",
      "Epoch 21/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.1151 - acc: 0.6770 - val_loss: 1.2117 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.16563\n",
      "Epoch 22/1000\n",
      "743/743 [==============================] - 2068s 3s/step - loss: 1.1362 - acc: 0.6891 - val_loss: 1.2426 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.16563\n",
      "Epoch 23/1000\n",
      "743/743 [==============================] - 2036s 3s/step - loss: 1.1357 - acc: 0.6824 - val_loss: 1.1881 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.16563\n",
      "Epoch 24/1000\n",
      "743/743 [==============================] - 2034s 3s/step - loss: 1.1205 - acc: 0.7012 - val_loss: 1.1731 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.16563\n",
      "Epoch 25/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1219 - acc: 0.7052 - val_loss: 1.1862 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.16563\n",
      "Epoch 26/1000\n",
      "743/743 [==============================] - 2031s 3s/step - loss: 1.1965 - acc: 0.7066 - val_loss: 1.3618 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.16563\n",
      "Epoch 27/1000\n",
      "743/743 [==============================] - 2034s 3s/step - loss: 1.2008 - acc: 0.7133 - val_loss: 1.2416 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.16563\n",
      "Epoch 28/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1437 - acc: 0.7120 - val_loss: 1.1780 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.16563\n",
      "Epoch 29/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1245 - acc: 0.7039 - val_loss: 1.1635 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.16563 to 1.16347, saving model to model1.h5\n",
      "Epoch 30/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.1224 - acc: 0.7093 - val_loss: 1.2272 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.16347\n",
      "Epoch 31/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1571 - acc: 0.6958 - val_loss: 1.1861 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.16347\n",
      "Epoch 32/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1139 - acc: 0.7039 - val_loss: 1.2063 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.16347\n",
      "Epoch 33/1000\n",
      "743/743 [==============================] - 2032s 3s/step - loss: 1.1030 - acc: 0.7241 - val_loss: 1.1745 - val_acc: 0.6774\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.16347\n",
      "Epoch 34/1000\n",
      "743/743 [==============================] - 2028s 3s/step - loss: 1.1105 - acc: 0.7133 - val_loss: 1.1684 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.16347\n",
      "Epoch 35/1000\n",
      "743/743 [==============================] - 2031s 3s/step - loss: 1.1072 - acc: 0.6878 - val_loss: 1.1776 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16347\n",
      "Epoch 36/1000\n",
      "743/743 [==============================] - 2034s 3s/step - loss: 1.0836 - acc: 0.7133 - val_loss: 1.1877 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.16347\n",
      "Epoch 37/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.1097 - acc: 0.7174 - val_loss: 1.2903 - val_acc: 0.6882\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.16347\n",
      "Epoch 38/1000\n",
      "743/743 [==============================] - 2031s 3s/step - loss: 1.1405 - acc: 0.7174 - val_loss: 1.2359 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.16347\n",
      "Epoch 39/1000\n",
      "743/743 [==============================] - 2029s 3s/step - loss: 1.1255 - acc: 0.7187 - val_loss: 1.1993 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.16347\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ce4d080>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_test, y_test),epochs=1000, batch_size=32, callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.47849462525818937\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0) \n",
    "print('Test Accuracy:', score[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tPerformance Table\n",
      "+---------------+----------------+------------+---------------+-----------+\n",
      "| No. of layers | Train Accuracy | Train loss | Test accuracy | Test loss |\n",
      "+---------------+----------------+------------+---------------+-----------+\n",
      "|       14      |     74.02      |   1.0509   |     68.82     |   1.2059  |\n",
      "|       14      |     71.87      |   1.1255   |     70.97     |   1.1993  |\n",
      "+---------------+----------------+------------+---------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable    \n",
    "x = PrettyTable()\n",
    " \n",
    "x.field_names = [\"No. of layers\", \"Train Accuracy\",\"Train loss\",\"Test accuracy\",'Test loss']\n",
    "x.add_row([14,74.02,1.0509,68.82,1.2059])\n",
    "x.add_row([14,71.87,1.1255,70.97,1.1993])\n",
    "\n",
    "\n",
    "print('\\t\\t\\t\\tPerformance Table')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "1) The data is imbalance, the count of each class is highly imbalance.\n",
    "\n",
    "2) The image size is reshaped.\n",
    "\n",
    "3) We build a neural network model with a total of 14 layers and use regularization to avoid overfitting.\n",
    "\n",
    "4) We use EarlyStopping to automatically stop the training of the model when the model is not imporving.\n",
    "\n",
    "5) The first model's train loss = 1.0509 and train accuracy = 74.02, and test loss = 1.2059 and test accuracy = 68.82\n",
    "\n",
    "6) The model is slightly overfit as the model performs well for training dataset and not for testing dstaset. \n",
    "\n",
    "7) The second model's train loss = 1.1255 and train accuracy = 71.87, and test loss = 1.1993 and test accuracy = 70.97\n",
    "\n",
    "8) The model is a good fit for both training dataset and testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Enhancement\n",
    "\n",
    "1) For model to perform better, we can use other modeling techniques like transform learning.\n",
    "\n",
    "2) As the dataset is very less to build a strong model, we can use data generator to generate new data from existing dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
